{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FND.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM25DeTcGPFiXAySKfMyDvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imanekn/Fake-News-Detection/blob/main/FND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nZRf8l-TTDUB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('Data-FakeRealCOVID.xlsx')"
      ],
      "metadata": {
        "id": "vxncbcwKYT2X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iZShj3XWYaid",
        "outputId": "4c84f165-5ed2-4fe8-d4f6-61aa10dd7a84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8fc20478-c7ae-431c-9e1b-fb6b0a61ca31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fc20478-c7ae-431c-9e1b-fb6b0a61ca31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fc20478-c7ae-431c-9e1b-fb6b0a61ca31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fc20478-c7ae-431c-9e1b-fb6b0a61ca31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id                                              tweet label\n",
              "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
              "1   2  States reported 1121 deaths a small rise from ...  real\n",
              "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
              "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
              "4   5  Populous states can generate large case counts...  real"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exploring Data**\n"
      ],
      "metadata": {
        "id": "7OL6GeeyZ4b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HUJvAQbJYb0A",
        "outputId": "20fd1ecb-14bf-478f-e5e0-be054da5bedb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c87a9746-1bbf-4fc2-a14a-fdd2fb2eeb2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6420.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3210.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1853.438696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1605.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3210.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4815.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6420.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c87a9746-1bbf-4fc2-a14a-fdd2fb2eeb2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c87a9746-1bbf-4fc2-a14a-fdd2fb2eeb2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c87a9746-1bbf-4fc2-a14a-fdd2fb2eeb2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                id\n",
              "count  6420.000000\n",
              "mean   3210.500000\n",
              "std    1853.438696\n",
              "min       1.000000\n",
              "25%    1605.750000\n",
              "50%    3210.500000\n",
              "75%    4815.250000\n",
              "max    6420.000000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if there are any missing values\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXt4204iY6tt",
        "outputId": "def1988e-0423-4ceb-8942-deea93270818"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id       0\n",
              "tweet    0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plotting**"
      ],
      "metadata": {
        "id": "t9yUGlwbZ0cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "sns.set(rc={'figure.figsize':(6,5)})"
      ],
      "metadata": {
        "id": "_4HTHX33Zdxj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='label', data=data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "e0junVP0Zfxh",
        "outputId": "9ec6473d-31d3-49fe-da97-c6e9f73641e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2d96d2e1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cleaning Data**"
      ],
      "metadata": {
        "id": "g0HIWmsRaJfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCqODN13aDc0",
        "outputId": "32b8400a-4a09-4a8f-f5f7-97fb87cf1e7f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "C5VxIZ6NatDV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem = PorterStemmer()"
      ],
      "metadata": {
        "id": "mVFV0F94bUqN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  port_stem = PorterStemmer()\n",
        "  stop_words = stopwords.words('english')\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'https\\S+', '', text, flags=re.MULTILINE)\n",
        "  text = re.sub(r'@\\S+', '', text, flags=re.MULTILINE)\n",
        "  text = re.sub(r'#\\S+', '', text, flags=re.MULTILINE)\n",
        "  \n",
        "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "  \n",
        "  text = re.sub('[^a-zA-Z]+', ' ', text) \n",
        "  \n",
        "  #text = [lemmatizer.lemmatize(word) for word in text.split() if not word in stopwords.words('english') and len(word)>2]\n",
        "  text = [port_stem.stem(word) for word in text.split() if not word in stopwords.words('english') and len(word)>2]\n",
        "  text = ' '.join(text)\n",
        "  \n",
        "  return text"
      ],
      "metadata": {
        "id": "5WG4y6gYa3CI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocess(x):\n",
        "  x = x.apply(lambda x : preprocess(x))\n",
        "\n",
        "  y = x.copy(deep=True)\n",
        "  for i in range(y.shape[0]):\n",
        "    y[i] = \"\".join(x[i])\n",
        "\n",
        "  return y"
      ],
      "metadata": {
        "id": "ROwXzxgigC0p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('Data-FakeRealCOVID.xlsx')"
      ],
      "metadata": {
        "id": "NfLTHi3fgpB9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"https/hgjjfdnkjgn #imane @imane , I read a book with 7 pages\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_S1XG82sdcR9",
        "outputId": "fbae578c-1702-4378-cb1f-bcf765fd1065"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'read book page'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"tweet\"] = data_preprocess(data[\"tweet\"])\n",
        "data[\"tweet\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZpCT4kpcZf9",
        "outputId": "a933323f-8bb8-4b44-fbc1-09ac27420bfc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc current report death gener discrep death c...\n",
              "1       state report death small rise last tuesday sou...\n",
              "2       polit correct woman almost use pandem excus re...\n",
              "3                  test laboratori india august test done\n",
              "4       popul state gener larg case count look new cas...\n",
              "                              ...                        \n",
              "6415      tiger test posit covid pleas stay away pet bird\n",
              "6416    autopsi prove covid blood clot pneumonia ought...\n",
              "6417    post claim covid vaccin alreadi develop caus w...\n",
              "6418                    aamir khan donat relief care fund\n",
              "6419    day sinc last case covid acquir local unknown ...\n",
              "Name: tweet, Length: 6420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading preprocessed data\n",
        "data.to_csv(\"Data-FakeRealCOVID1.csv\", index=False)"
      ],
      "metadata": {
        "id": "J_hS8CmYdN-Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Features Extraction**"
      ],
      "metadata": {
        "id": "rDYaTclkhNsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Data-FakeRealCOVID1.csv\")"
      ],
      "metadata": {
        "id": "F0Dy0mfMiDyW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EEpkf627iggv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.isnull().any(axis=1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "omrfM55hi2Wr",
        "outputId": "7a2b6e2b-3385-4102-9031-264c49230ba6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-70712492-5726-4945-af1d-e9e8ded4087a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4286</th>\n",
              "      <td>4287</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4697</th>\n",
              "      <td>4698</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70712492-5726-4945-af1d-e9e8ded4087a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70712492-5726-4945-af1d-e9e8ded4087a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70712492-5726-4945-af1d-e9e8ded4087a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id tweet label\n",
              "4286  4287   NaN  fake\n",
              "4697  4698   NaN  fake"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "DLRIXXj9jecF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['tweet']\n",
        "Y = df['label']"
      ],
      "metadata": {
        "id": "6DKboGeEhNYO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label\"].replace({\"real\": 1, \"fake\": 0}, inplace=True)"
      ],
      "metadata": {
        "id": "ixSIzewf3ErA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer() \n",
        "X = tfidf_vectorizer.fit_transform(X).toarray()\n"
      ],
      "metadata": {
        "id": "AKqqpw6tiNxZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = Y.to_numpy()\n",
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFgqx9oPktMu",
        "outputId": "0beece02-8f85-41f4-f84e-dbe3a1121969"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.c_[X, label]"
      ],
      "metadata": {
        "id": "3XholXw83-g_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_names = tfidf_vectorizer.get_feature_names() + ['label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-9rAlNmsJ-j",
        "outputId": "a6ad9f64-283b-45e2-911c-36bdc683650e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(array, index=[0+i for i in range(6418)], columns=features_names)"
      ],
      "metadata": {
        "id": "dxwamZPktwq1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv('features.csv' , index=False)"
      ],
      "metadata": {
        "id": "oK7ueogM1TAJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model**"
      ],
      "metadata": {
        "id": "xH5T3Y_0r3mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('features.csv')"
      ],
      "metadata": {
        "id": "9CTXb3ksvzv2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "4AorgsgBYsng"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(df.to_numpy())"
      ],
      "metadata": {
        "id": "KeClqLSlKkss"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o73PLOaCLBH-",
        "outputId": "49fc9e2d-0f88-4ff5-b916-996240478c36"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.4864, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "l1QumA3yLGE9",
        "outputId": "e35d7d29-6e84-44cd-90cb-a254b08b4afd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9f7222f0-8fdd-413c-8f42-a4f5a0f11548\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaj</th>\n",
              "      <th>aamir</th>\n",
              "      <th>aamp</th>\n",
              "      <th>aaradhya</th>\n",
              "      <th>ababa</th>\n",
              "      <th>abacha</th>\n",
              "      <th>abakaliki</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abat</th>\n",
              "      <th>abbasi</th>\n",
              "      <th>abbott</th>\n",
              "      <th>abbrevi</th>\n",
              "      <th>abc</th>\n",
              "      <th>abdic</th>\n",
              "      <th>abdul</th>\n",
              "      <th>abdulaziz</th>\n",
              "      <th>abhigyan</th>\n",
              "      <th>abhishek</th>\n",
              "      <th>abia</th>\n",
              "      <th>abid</th>\n",
              "      <th>abil</th>\n",
              "      <th>abl</th>\n",
              "      <th>abnorm</th>\n",
              "      <th>aboard</th>\n",
              "      <th>abort</th>\n",
              "      <th>abou</th>\n",
              "      <th>abound</th>\n",
              "      <th>aboveinfl</th>\n",
              "      <th>aboveremain</th>\n",
              "      <th>abraham</th>\n",
              "      <th>abruptli</th>\n",
              "      <th>abscbn</th>\n",
              "      <th>absenc</th>\n",
              "      <th>absent</th>\n",
              "      <th>absente</th>\n",
              "      <th>absolut</th>\n",
              "      <th>absorb</th>\n",
              "      <th>abt</th>\n",
              "      <th>abubakar</th>\n",
              "      <th>abuja</th>\n",
              "      <th>...</th>\n",
              "      <th>yojanapmsbi</th>\n",
              "      <th>york</th>\n",
              "      <th>yorker</th>\n",
              "      <th>yorkshir</th>\n",
              "      <th>youll</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>your</th>\n",
              "      <th>youtc</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtub</th>\n",
              "      <th>youv</th>\n",
              "      <th>yvonn</th>\n",
              "      <th>zack</th>\n",
              "      <th>zambal</th>\n",
              "      <th>zambia</th>\n",
              "      <th>zamfara</th>\n",
              "      <th>zanzibar</th>\n",
              "      <th>zaria</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zee</th>\n",
              "      <th>zekiri</th>\n",
              "      <th>zero</th>\n",
              "      <th>zhong</th>\n",
              "      <th>zhoushan</th>\n",
              "      <th>ziberi</th>\n",
              "      <th>zika</th>\n",
              "      <th>zinc</th>\n",
              "      <th>zithromax</th>\n",
              "      <th>zomato</th>\n",
              "      <th>zombi</th>\n",
              "      <th>zone</th>\n",
              "      <th>zonecityspecif</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zookeep</th>\n",
              "      <th>zoolog</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zydu</th>\n",
              "      <th>zyphr</th>\n",
              "      <th>label.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  7943 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f7222f0-8fdd-413c-8f42-a4f5a0f11548')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f7222f0-8fdd-413c-8f42-a4f5a0f11548 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f7222f0-8fdd-413c-8f42-a4f5a0f11548');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   aaj  aamir  aamp  aaradhya  ababa  ...  zoolog  zoom  zydu  zyphr  label.1\n",
              "0  0.0    0.0   0.0       0.0    0.0  ...     0.0   0.0   0.0    0.0      1.0\n",
              "1  0.0    0.0   0.0       0.0    0.0  ...     0.0   0.0   0.0    0.0      1.0\n",
              "2  0.0    0.0   0.0       0.0    0.0  ...     0.0   0.0   0.0    0.0      0.0\n",
              "3  0.0    0.0   0.0       0.0    0.0  ...     0.0   0.0   0.0    0.0      1.0\n",
              "4  0.0    0.0   0.0       0.0    0.0  ...     0.0   0.0   0.0    0.0      1.0\n",
              "\n",
              "[5 rows x 7943 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.pop('label.1')\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8Ke4BSsKu9T",
        "outputId": "7b8dd32d-233e-41f7-8b46-3a2d884720b1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1.0\n",
              "1       1.0\n",
              "2       0.0\n",
              "3       1.0\n",
              "4       1.0\n",
              "       ... \n",
              "6413    0.0\n",
              "6414    0.0\n",
              "6415    0.0\n",
              "6416    0.0\n",
              "6417    1.0\n",
              "Name: label.1, Length: 6418, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = torch.tensor(y)\n",
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZts3QQuLlia",
        "outputId": "8bf1d41c-b734-4c9a-c07e-6b8195734a9e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 0.,  ..., 0., 0., 1.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(data,targets,test_size=0.2)"
      ],
      "metadata": {
        "id": "Ro_0oGBgL223"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBFnt35IbzUl",
        "outputId": "307ecae9-b562-4c9b-803b-737fd07306b5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5134, 7943])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYUY_S4Jei-8",
        "outputId": "7b5a27c4-9b2c-4c8f-ea41-99fc55231dfe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1284, 7943])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
      ],
      "metadata": {
        "id": "J2Fn7byiwXRB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "X_val = torch.tensor(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjgkPPF7wkhs",
        "outputId": "90962f0d-7a0d-4f8f-95d6-86391a9b20c4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeoMlSVweqxJ",
        "outputId": "8012b7cf-c663-4acc-ca8d-1ab0b64411b4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = torch.tensor(y_train)\n",
        "y_test = torch.tensor(y_test)\n",
        "y_val = torch.tensor(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_myaqa2JwoED",
        "outputId": "4164ef96-8ff9-49aa-93ac-ac301191cdf4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.to(torch.float32)\n",
        "y_test = y_test.to(torch.float32)\n",
        "y_val = y_val.to(torch.float32)\n"
      ],
      "metadata": {
        "id": "cwCEex520QU_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crer une classe qui hrite de Dataset et redfinit les mthodes comme susmentionn\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, targets):\n",
        "        super(MyDataset, self)\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.targets[idx]\n",
        "    def __len__(self):\n",
        "        return len(self.targets)"
      ],
      "metadata": {
        "id": "7T7EE-c50CDF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(X_train,y_train)\n",
        "val_dataset = MyDataset(X_val,y_val)\n",
        "test_dataset = MyDataset(X_test,y_test)"
      ],
      "metadata": {
        "id": "BJVR6EuHRWYN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "metadata": {
        "id": "PETW7iRvSCBn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "Ry1tofxXThPC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_Dataloader = DataLoader(train_dataset , batch_size)\n",
        "val_Dataloader = DataLoader(val_dataset , batch_size)\n",
        "test_Dataloader = DataLoader(test_dataset , batch_size)"
      ],
      "metadata": {
        "id": "-dT6hsVTSddF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_Dataloader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGtj3p4KUFSM",
        "outputId": "71625bac-dd90-4d48-aa66-facd7ab4b066"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3850"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyNN,self).__init__()\n",
        "    self.input_layer = nn.Linear(7943, 64)\n",
        "    self.hidden_layer = nn.Linear(64,32)\n",
        "    self.output_layer = nn.Linear(32,1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.input_layer(x))\n",
        "    x = F.relu(self.hidden_layer(x))\n",
        "    return torch.sigmoid(self.output_layer(x))\n",
        " "
      ],
      "metadata": {
        "id": "aUJHKkXgi5in"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MyNN = nn.Sequential(nn.Linear(train_data.shape[1], 64),nn.ReLU(),nn.Linear(64, 2))"
      ],
      "metadata": {
        "id": "hGdtYgVCcKQz"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyNN()"
      ],
      "metadata": {
        "id": "t_M9UH6nYcIK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "7ygSizqaoCjS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "u13jTtJ8r336"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dfinir une fonction d'optimisation des cot, On choisira 0.001 pour le learning rate.\n",
        "#optimizer = optim.Adadelta(model.parameters(), lr=100)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "QuxfN4OhrVfP"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5"
      ],
      "metadata": {
        "id": "6q36_o_tr6Kq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# on essaye pour le premier\n",
        "losses_train = []\n",
        "losses_val = []\n",
        "# mode train\n",
        "\n",
        "for i in range(epochs):\n",
        "    # erreur dand tout l'epoch\n",
        "    loss = 0\n",
        "    model.train()\n",
        "    # pour chacun des batches\n",
        "    for data_ , targets_ in train_Dataloader:\n",
        "        # on va rinitialiser l'optimisateur\n",
        "        optimizer.zero_grad()\n",
        "        # on calcule les prdictions de nos donnes du batch\n",
        "        pred = model(data_.float())\n",
        "        # on calcule la moyenne des erreurs\n",
        "        erreur = loss_function(pred,targets_.reshape(-1,1))\n",
        "        # on a calculer l'erreur y- et  est en fonction des wi \n",
        "        # on fait la backpropagation qui va calculer d(erreur)/d(wi)   avec un chainnage de drive d(erreur)/d(an)*d(an)/d(a(n-1))*...*d(a(n-r))/d(z(n-r))*d(z(n-r))/wi \n",
        "        # ce chainage (trac) pendant la forward propagation pour calculer l'erreur\n",
        "        erreur.backward()\n",
        "        # cette backpropagation va donc nos donner nos gradients d(erreur)/d(wi)\n",
        "        # on va utiliser ces gradients pour calculer les nouveaux weights\n",
        "        # wi = wi-rate*gradient     (gradient = d(erreur)/d(wi))\n",
        "        # cette etape est faite par l'optimisateur\n",
        "        optimizer.step()\n",
        "        loss+=erreur.item()\n",
        "    losses_train.append(loss/len(X_train))\n",
        "    model.eval()\n",
        "    loss=0\n",
        "    target_size = 0\n",
        "    # on arrete de traquer les changements pour le calcul du gradient\n",
        "    with torch.no_grad():\n",
        "        for data_,targets_ in val_Dataloader:\n",
        "            pred = model(data_.float())\n",
        "            for t in range(len(pred)):\n",
        "                print(pred[t], \" \",targets_[t])\n",
        "            erreur = loss_function(pred,targets_.reshape(-1,1))\n",
        "            loss+=erreur.item()\n",
        "            print(loss)\n",
        "        losses_val.append(loss/len(X_val))\n",
        "        '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Dm7N6Mfeeaku",
        "outputId": "2628348a-5bd2-4c51-add9-0c0221c33942"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# on essaye pour le premier\\nlosses_train = []\\nlosses_val = []\\n# mode train\\n\\nfor i in range(epochs):\\n    # erreur dand tout l\\'epoch\\n    loss = 0\\n    model.train()\\n    # pour chacun des batches\\n    for data_ , targets_ in train_Dataloader:\\n        # on va rinitialiser l\\'optimisateur\\n        optimizer.zero_grad()\\n        # on calcule les prdictions de nos donnes du batch\\n        pred = model(data_.float())\\n        # on calcule la moyenne des erreurs\\n        erreur = loss_function(pred,targets_.reshape(-1,1))\\n        # on a calculer l\\'erreur y- et  est en fonction des wi \\n        # on fait la backpropagation qui va calculer d(erreur)/d(wi)   avec un chainnage de drive d(erreur)/d(an)*d(an)/d(a(n-1))*...*d(a(n-r))/d(z(n-r))*d(z(n-r))/wi \\n        # ce chainage (trac) pendant la forward propagation pour calculer l\\'erreur\\n        erreur.backward()\\n        # cette backpropagation va donc nos donner nos gradients d(erreur)/d(wi)\\n        # on va utiliser ces gradients pour calculer les nouveaux weights\\n        # wi = wi-rate*gradient     (gradient = d(erreur)/d(wi))\\n        # cette etape est faite par l\\'optimisateur\\n        optimizer.step()\\n        loss+=erreur.item()\\n    losses_train.append(loss/len(X_train))\\n    model.eval()\\n    loss=0\\n    target_size = 0\\n    # on arrete de traquer les changements pour le calcul du gradient\\n    with torch.no_grad():\\n        for data_,targets_ in val_Dataloader:\\n            pred = model(data_.float())\\n            for t in range(len(pred)):\\n                print(pred[t], \" \",targets_[t])\\n            erreur = loss_function(pred,targets_.reshape(-1,1))\\n            loss+=erreur.item()\\n            print(loss)\\n        losses_val.append(loss/len(X_val))\\n        '"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " '''\n",
        " for i in range(epochs):\n",
        "  model.train()\n",
        "  train_loss = 0.0\n",
        "  for data_, targets_ in train_Dataloader :\n",
        "\n",
        "    data = data.float()\n",
        "    print(data.dtype)\n",
        "    pred_targets = model(torch.flatten(data, start_dim=1))\n",
        "    loss = loss_function(pred_targets, targets_.long())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_Dataloader)\n",
        "\n",
        "    # boucle de validation:\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad :\n",
        "      for data, targets in val_Dataloader :\n",
        "        pred_targets = model(torch.flatten(data, start_dim=1))\n",
        "        loss = loss_function(pred_targets, targets)\n",
        "        valid_loss += loss.item()\n",
        "        correct += torch.sum(torch.argmax(pred_targets, dim=1) == targets).item()\n",
        "\n",
        "      valid_loss /= len(val_Dataloader)\n",
        "\n",
        "      correct /= len(val_Dataloader.dataset)\n",
        "\n",
        "    print(f\"epoch: {i}, train loss: {train_loss:.4f}, validation loss: {valid_loss:.4f}, correct predictions: {correct*100:.2f}%\")\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "5rQ4GsiKr-zf",
        "outputId": "35097cc4-0456-47dd-db95-40190f78913e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor i in range(epochs):\\n model.train()\\n train_loss = 0.0\\n for data_, targets_ in train_Dataloader :\\n\\n   data = data.float()\\n   print(data.dtype)\\n   pred_targets = model(torch.flatten(data, start_dim=1))\\n   loss = loss_function(pred_targets, targets_.long())\\n   optimizer.zero_grad()\\n   loss.backward()\\n   optimizer.step()\\n   train_loss += loss.item()\\n\\n   train_loss /= len(train_Dataloader)\\n\\n   # boucle de validation:\\n   valid_loss = 0\\n   correct = 0\\n   \\n\\n   model.eval()\\n\\n   with torch.no_grad :\\n     for data, targets in val_Dataloader :\\n       pred_targets = model(torch.flatten(data, start_dim=1))\\n       loss = loss_function(pred_targets, targets)\\n       valid_loss += loss.item()\\n       correct += torch.sum(torch.argmax(pred_targets, dim=1) == targets).item()\\n\\n     valid_loss /= len(val_Dataloader)\\n\\n     correct /= len(val_Dataloader.dataset)\\n\\n   print(f\"epoch: {i}, train loss: {train_loss:.4f}, validation loss: {valid_loss:.4f}, correct predictions: {correct*100:.2f}%\")\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_model(epochs):\n",
        "  for i in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for data_, targets_ in train_Dataloader :\n",
        "      \n",
        "      pred_targets = (data_.float())\n",
        "      loss = loss_function(pred_targets,targets_.reshape(-1,1))\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "    \n",
        "    train_loss /= len(train_Dataloader)\n",
        "\n",
        "    # boucle de validation:\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad :\n",
        "      for data_, targets_ in val_Dataloader :\n",
        "        pred_targets = model(data_.float())\n",
        "        loss = loss_function(pred_targets,targets_.reshape(-1,1))\n",
        "        valid_loss += loss.item()\n",
        "        correct += torch.sum(torch.argmax(pred_targets, dim=1) == targets).item()\n",
        "      \n",
        "      valid_loss /= len(val_Dataloader)\n",
        "\n",
        "      correct /= len(val_Dataloader.dataset)\n",
        "\n",
        "    print(f\"epoch: {i}, train loss: {train_loss:.4f}, validation loss: {valid_loss:.4f}, correct predictions: {correct*100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "euCOXl6rzbro"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_model(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "N3hRfg--V2PB",
        "outputId": "91163315-b124-4004-ba5e-37d133d07961"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-72d633223f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-d294dbe5e297>\u001b[0m in \u001b[0;36mtraining_model\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mpred_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iBlPHqUbXmpV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}